{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWzdMuqbD7Lp",
        "outputId": "112d1176-0f8d-47cf-9d70-fe24ffaa4537"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "\n",
        "from google.colab import files\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Lh2hPwSS-QBq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the trining set, dataset is from the french to english\n",
        "!wget https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_train.txt\n",
        "# Download validation set pairs.\n",
        "!wget https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_val.txt\n",
        "# Retrieve the test dataset.\n",
        "!wget https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMQQThfpEHBa",
        "outputId": "dc4ece8e-008b-402d-eb48-a22b965418e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 16:43:19--  https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5518306 (5.3M) [text/plain]\n",
            "Saving to: ‘hun_eng_pairs_train.txt’\n",
            "\n",
            "hun_eng_pairs_train 100%[===================>]   5.26M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-11-23 16:43:19 (78.2 MB/s) - ‘hun_eng_pairs_train.txt’ saved [5518306/5518306]\n",
            "\n",
            "--2023-11-23 16:43:19--  https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_val.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 646226 (631K) [text/plain]\n",
            "Saving to: ‘hun_eng_pairs_val.txt’\n",
            "\n",
            "hun_eng_pairs_val.t 100%[===================>] 631.08K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-11-23 16:43:20 (15.3 MB/s) - ‘hun_eng_pairs_val.txt’ saved [646226/646226]\n",
            "\n",
            "--2023-11-23 16:43:20--  https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 646226 (631K) [text/plain]\n",
            "Saving to: ‘hun_eng_pairs_test.txt’\n",
            "\n",
            "hun_eng_pairs_test. 100%[===================>] 631.08K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-11-23 16:43:20 (19.3 MB/s) - ‘hun_eng_pairs_test.txt’ saved [646226/646226]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('hun_eng_pairs_train.txt') as file:\n",
        "  train = [line.rstrip() for line in file]"
      ],
      "metadata": {
        "id": "6ViLQvIvEev-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqizQY6HEiHN",
        "outputId": "43011f22-70db-4071-f0a9-fa088476e91d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Teszek rá, mit mondasz!<sep>I don't care what you say.\",\n",
              " 'Több olyan ember kell nekünk a csapatba, mint amilyen te vagy.<sep>We need more people like you on our team.',\n",
              " 'Vigyázz a gyerekeimre!<sep>Take care of my children.',\n",
              " 'Miért van szüksége önöknek két kerékpárra?<sep>Why do you need two bicycles?']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "separator = '<sep>'\n",
        "train_input,train_input_target = map(list,zip(*[pair.split(separator) for pair in train]))"
      ],
      "metadata": {
        "id": "And-eYufEomp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txQZjyzmEuup",
        "outputId": "d5ccdea2-6b6c-4ff5-a936-1a16451a69b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Teszek rá, mit mondasz!',\n",
              " 'Több olyan ember kell nekünk a csapatba, mint amilyen te vagy.',\n",
              " 'Vigyázz a gyerekeimre!',\n",
              " 'Miért van szüksége önöknek két kerékpárra?']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_target[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvME_wmrExS4",
        "outputId": "7d655aaf-f119-4a34-851e-6e0c1b2e24bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I don't care what you say.\",\n",
              " 'We need more people like you on our team.',\n",
              " 'Take care of my children.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_unicode(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',s)\n",
        "    if unicodedata.category(c)!='Mn')"
      ],
      "metadata": {
        "id": "-_Bh75P3Ezun"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(s):\n",
        "  s = normalize_unicode(s)\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = s.strip()\n",
        "  return s"
      ],
      "metadata": {
        "id": "r_rVSBNXE2VG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [preprocess_sentence(s) for s in train_input]\n",
        "train_data_target = [preprocess_sentence(s) for s in train_input_target]"
      ],
      "metadata": {
        "id": "s8hlv4eRE7U3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_target[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xm8S84sE_LP",
        "outputId": "f165a163-a908-4792-d48c-29223d297a6a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I don't care what you say .\",\n",
              " 'We need more people like you on our team .',\n",
              " 'Take care of my children .']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhXPGnJoFCdE",
        "outputId": "23ae70b5-782e-464a-b144-9740530fc694"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Teszek ra , mit mondasz !',\n",
              " 'Tobb olyan ember kell nekunk a csapatba , mint amilyen te vagy .',\n",
              " 'Vigyazz a gyerekeimre !']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_target_sentence(sentences):\n",
        "  tagged_sentence = map(lambda s: (' ').join(['<sos>',s,'<eos>']),sentences)\n",
        "  return list(tagged_sentence)"
      ],
      "metadata": {
        "id": "PVKLUwJoFGRf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_target_tagged = tag_target_sentence(train_data_target)"
      ],
      "metadata": {
        "id": "FTKwoO1eFIOt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_target_tagged[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zblufWyWFKgE",
        "outputId": "ad8a1e54-929d-4082-de6d-d55ec7af6a84"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<sos> I don't care what you say . <eos>\",\n",
              " '<sos> We need more people like you on our team . <eos>',\n",
              " '<sos> Take care of my children . <eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenized the source sentence\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
        "source_tokenizer.fit_on_texts(train_data)"
      ],
      "metadata": {
        "id": "5FA8uyg-FRvR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_vocab_size = len(source_tokenizer.word_index)+1\n",
        "source_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwZLxbj8FWLq",
        "outputId": "294ce10a-abf9-40c5-bc72-6ad35214a171"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38539"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the target sentence\n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
        "target_tokenizer.fit_on_texts(train_data_target_tagged)"
      ],
      "metadata": {
        "id": "FE1MXinoFaIT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "print(target_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6RR0w4SFl1N",
        "outputId": "1e5fb4c1-d0e2-4258-e4c0-0e64b0b85fb3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoder_inputs = source_tokenizer.texts_to_sequences(train_data)"
      ],
      "metadata": {
        "id": "ZD24GWBcFsXH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_encoder_inputs[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcv51a51FvIP",
        "outputId": "e45adeb9-6144-4fe9-d744-31dde8586a4b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1395, 91, 4, 27, 1080, 10], [153, 56, 145, 17, 152, 3, 7232, 4, 45, 1670, 44, 23, 2], [1026, 3, 8933, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(source_tokenizer.sequences_to_texts(train_encoder_inputs[:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JisWZd3FvYg",
        "outputId": "48af7506-d56c-4ae0-c76a-66752ed38fee"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['teszek ra , mit mondasz !', 'tobb olyan ember kell nekunk a csapatba , mint amilyen te vagy .', 'vigyazz a gyerekeimre !']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_decoder_inputs_targets(sentences,tokenizer):\n",
        "  seqs = tokenizer.texts_to_sequences(sentences)\n",
        "  decoder_input = [s[:-1] for s in seqs]\n",
        "  decoder_target = [s[1:] for s in seqs]\n",
        "  return decoder_input , decoder_target\n"
      ],
      "metadata": {
        "id": "WbdCA2kFFwnu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_decoder_inputs, train_decoder_targets = generate_decoder_inputs_targets(train_data_target_tagged,target_tokenizer)"
      ],
      "metadata": {
        "id": "aePtklsaF2hM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_decoder_inputs[0], train_decoder_targets[0])\n",
        "print(target_tokenizer.sequences_to_texts(train_decoder_inputs[:1]),\n",
        "      target_tokenizer.sequences_to_texts(train_decoder_targets[:1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOVXpfhdGI_q",
        "outputId": "7bdcee2a-897a-4db7-9c5b-d2fba7095e40"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 23, 306, 28, 7, 151, 4] [5, 23, 306, 28, 7, 151, 4, 3]\n",
            "[\"<sos> i don't care what you say .\"] [\"i don't care what you say . <eos>\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_encoding_len = len(max(train_encoder_inputs, key=len))\n",
        "max_encoding_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYy0EpSEJOer",
        "outputId": "18f20b04-b77c-4bae-83bc-2b9dbfff7abf"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_decoding_len = len(max(train_decoder_inputs, key=len))\n",
        "max_decoding_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grOJyGjNJdft",
        "outputId": "1a0de024-1e37-4d07-e6e4-35efefbeec4e"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_train_encoder_inputs = pad_sequences(train_encoder_inputs, max_encoding_len, padding='post', truncating='post')\n",
        "padded_train_decoder_inputs = pad_sequences(train_decoder_inputs, max_decoding_len, padding='post', truncating='post')\n",
        "padded_train_decoder_targets = pad_sequences(train_decoder_targets, max_decoding_len, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "Fyca0gbjJfQA"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_train_encoder_inputs[0])\n",
        "print(padded_train_decoder_inputs[0])\n",
        "print(padded_train_decoder_targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1rmTBahJqhy",
        "outputId": "1981a0fd-34ba-4635-d7fd-3451b05dbccd"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1395   91    4   27 1080   10    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0]\n",
            "[  2   5  23 306  28   7 151   4   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "[  5  23 306  28   7 151   4   3   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for all the unknown words it will add unk\n",
        "target_tokenizer.sequences_to_texts([padded_train_decoder_inputs[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjtc393PKb0B",
        "outputId": "2e880a6f-dec7-4b0e-86ee-2b970caf4cda"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<sos> i don't care what you say . <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crYc04fVA9-Q"
      },
      "source": [
        "#**All preprocessign together for validation set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "nqDKmrcYBMT9"
      },
      "outputs": [],
      "source": [
        "with open('hun_eng_pairs_val.txt') as file:\n",
        "  val = [line.rstrip() for line in file]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "soIMr8bNBDFu"
      },
      "outputs": [],
      "source": [
        "def process_dataset(dataset):\n",
        "\n",
        "  # Split the Hungarian and English sentences into separate lists.\n",
        "  input, output = map(list, zip(*[pair.split(separator) for pair in dataset]))\n",
        "\n",
        "  # Unicode normalization and inserting spaces around punctuation.\n",
        "  preprocessed_input = [preprocess_sentence(s) for s in input]\n",
        "  preprocessed_output = [preprocess_sentence(s) for s in output]\n",
        "\n",
        "  # Tag target sentences with <sos> and <eos> tokens.\n",
        "  tagged_preprocessed_output = tag_target_sentence(preprocessed_output)\n",
        "\n",
        "  # Vectorize encoder source sentences.\n",
        "  encoder_inputs = source_tokenizer.texts_to_sequences(preprocessed_input)\n",
        "\n",
        "  # Vectorize and create decoder input and target sentences.\n",
        "  decoder_inputs, decoder_targets = generate_decoder_inputs_targets(tagged_preprocessed_output,\n",
        "                                                                    target_tokenizer)\n",
        "\n",
        "  # Pad all collections.\n",
        "  padded_encoder_inputs = pad_sequences(encoder_inputs, max_encoding_len, padding='post', truncating='post')\n",
        "  padded_decoder_inputs = pad_sequences(decoder_inputs, max_decoding_len, padding='post', truncating='post')\n",
        "  padded_decoder_targets = pad_sequences(decoder_targets, max_decoding_len, padding='post', truncating='post')\n",
        "\n",
        "  return padded_encoder_inputs, padded_decoder_inputs, padded_decoder_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "xHyzhKeTBNt8"
      },
      "outputs": [],
      "source": [
        "# Process validation dataset\n",
        "padded_val_encoder_inputs, padded_val_decoder_inputs, padded_val_decoder_targets = process_dataset(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "n16en-ChBXKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e2bd5c-8c00-41ef-956c-0b56b79531ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,    4,   38, 2948,    2,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [1056,   74,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "padded_val_encoder_inputs[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez7HLvX9B2C2"
      },
      "source": [
        "##**Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "JO_Wx3UlB6UC"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "default_dropout=0.2\n",
        "batch_size = 32\n",
        "epochs = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-YeIzAF2yO"
      },
      "source": [
        "###***Encoder***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Attention_Mechanism_for_the_Machine_Translation**"
      ],
      "metadata": {
        "id": "Y8GqeJLIEOpK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "Sfw0Xyvf7Drc"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # No masking here. We'll handle it ourselves.\n",
        "        self.embedding = layers.Embedding(source_vocab_size,\n",
        "                                          embedding_dim,\n",
        "                                          name='encoder_embedding_layer')\n",
        "\n",
        "        # return_sequences is set to True this time.\n",
        "        self.lstm = layers.LSTM(hidden_dim,\n",
        "                                return_sequences=True,\n",
        "                                return_state=True,\n",
        "                                name='encoder_lstm')\n",
        "\n",
        "    def call(self, input):\n",
        "        embeddings = self.embedding(input)\n",
        "\n",
        "        # output_seq will hold the encoder's hidden states from each time step.\n",
        "        output_seq, state_h, state_c = self.lstm(embeddings)\n",
        "\n",
        "        return output_seq, state_h, state_c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#made our own encoder , with the own Encoder class\n",
        "test_encoder = Encoder(source_vocab_size, embedding_dim, hidden_dim)"
      ],
      "metadata": {
        "id": "W6vwv2O6An4t"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_encoder_batch = padded_train_encoder_inputs[:3]\n",
        "test_encoder_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCsygmWEA4wA",
        "outputId": "f3444662-6091-4a88-c751-e569fbf7ea0c"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1395,   91,    4,   27, 1080,   10,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [ 153,   56,  145,   17,  152,    3, 7232,    4,   45, 1670,   44,\n",
              "          23,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [1026,    3, 8933,   10,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_encoder_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BUT3nE7NZ1W",
        "outputId": "b1842c77-01da-4f56-85fe-8329b86532c1"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_encoder_outputs, state_h, state_c = test_encoder(test_encoder_batch)"
      ],
      "metadata": {
        "id": "1NQUgTQZNrcb"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_encoder_outputs.shape)\n",
        "print(state_h.shape)\n",
        "print(state_c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYy6lYyuPCxj",
        "outputId": "1af9801a-be5b-4c73-89ea-6a994f168177"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 37, 256)\n",
            "(3, 256)\n",
            "(3, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Hands on Attention**"
      ],
      "metadata": {
        "id": "xmZwtyq9Pwmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample encoder LSTM output for single sequence of length 4., hidden state from the encoder\n",
        "encoder_out = tf.constant([[1., 2., 3.],\n",
        "                           [2., 3., 4.],\n",
        "                           [3., 4., 5.],\n",
        "                           [4., 5. ,6.]])"
      ],
      "metadata": {
        "id": "k5Bhytc2PJ5T"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t3r_Y2OPSrm",
        "outputId": "0046fba0-f185-4171-ec5b-9236be26ece6"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [2., 3., 4.],\n",
              "       [3., 4., 5.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('encoder_out shape: {}'.format(encoder_out.shape))\n",
        "print('Number of timesteps: {}'.format(encoder_out.shape[0]))\n",
        "print('Number of hidden dimensions: {}'.format(encoder_out.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdA-iQWmPUhU",
        "outputId": "d972371d-1521-42f3-ea27-962288cdca05"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_out shape: (4, 3)\n",
            "Number of timesteps: 4\n",
            "Number of hidden dimensions: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample decoder LSTM output for a single timestep. hidden state from decoder at any timestep\n",
        "decoder_out = tf.constant([[1., 3., 5.]])"
      ],
      "metadata": {
        "id": "jIdICop7PYOn"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('decoder_out shape: {}'.format(decoder_out.shape))\n",
        "print('Number of timesteps: {}'.format(decoder_out.shape[0]))\n",
        "print('Number of hidden dimensions: {}'.format(decoder_out.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5en-lAaPr4k",
        "outputId": "b5b53d9f-64d6-4344-d862-ea488a7cb104"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_out shape: (1, 3)\n",
            "Number of timesteps: 1\n",
            "Number of hidden dimensions: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.transpose(encoder_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV7ClmtoPtQh",
        "outputId": "48068990-31fc-446a-afbc-64a87a29d973"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[1., 2., 3., 4.],\n",
              "       [2., 3., 4., 5.],\n",
              "       [3., 4., 5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The *tf.matmul* function can perform the transpose and the dot product in one step to yield the attention scores.<br>\n",
        "attention_scores = tf.matmul(decoder_out, encoder_out, transpose_b=True)\n",
        "print(attention_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBWc3NxYP5Km",
        "outputId": "516f57a6-3f94-4879-8d75-f03176d602ee"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[22. 31. 40. 49.]], shape=(1, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = tf.keras.activations.softmax(attention_scores, axis=-1)\n",
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9iler30QIpv",
        "outputId": "2fcf2fbc-0e64-4156-dffd-8c0fa8846afa"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[1.8792971e-12 1.5228100e-08 1.2339458e-04 9.9987662e-01]], shape=(1, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = tf.keras.activations.softmax(attention_scores, axis=-1)\n",
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8-g9v10QVp4",
        "outputId": "010fb5dd-fddd-424b-f0a8-3cc4f1e146a4"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[1.8792971e-12 1.5228100e-08 1.2339458e-04 9.9987662e-01]], shape=(1, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = tf.matmul(attention_weights, encoder_out)\n",
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPoh-P-zYQRf",
        "outputId": "b7a69572-9bf9-4d09-e5fe-39410f9af08d"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[3.9998767 4.9998765 5.999877 ]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttention(tf.keras.Model):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super(LuongAttention, self).__init__()\n",
        "    self.w = layers.Dense(hidden_dim, name='encoder_outputs_dense')\n",
        "  def call(self, inputs):\n",
        "    encoder_output_seq, decoder_output = inputs\n",
        "    z = self.w(encoder_output_seq)\n",
        "    attention_scores = tf.matmul(decoder_output, z, transpose_b=True)\n",
        "    attention_weights = tf.keras.activations.softmax(attention_scores, axis=-1)\n",
        "    context = tf.matmul(attention_weights, encoder_output_seq)\n",
        "    return attention_weights, context\n"
      ],
      "metadata": {
        "id": "eRB-9pkYQeh4"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.embedding_layer = layers.Embedding(vocab_size,\n",
        "                                            embedding_dim,\n",
        "                                            name='decoder_embedding_layer')\n",
        "\n",
        "    self.lstm = layers.LSTM(hidden_dim,\n",
        "                            return_sequences=True,\n",
        "                            return_state=True,\n",
        "                            name='decoder_lstm')\n",
        "\n",
        "    self.attention = LuongAttention(hidden_dim)\n",
        "\n",
        "    self.w = tf.keras.layers.Dense(hidden_dim, activation='tanh', name='attended_outputs_dense')\n",
        "\n",
        "    self.dense = layers.Dense(vocab_size, name='decoder_dense')\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    decoder_input, encoder_output_seq, lstm_state = inputs\n",
        "    embeddings = self.embedding_layer(decoder_input)\n",
        "\n",
        "    decoder_output, state_h, state_c = self.lstm(embeddings, initial_state=lstm_state)\n",
        "\n",
        "    weights, context = self.attention([encoder_output_seq, decoder_output])\n",
        "\n",
        "    decoder_output_with_attention = self.w(tf.concat(\n",
        "        [tf.squeeze(context, 1), tf.squeeze(decoder_output, 1)], -1))\n",
        "\n",
        "    logits = self.dense(decoder_output_with_attention)\n",
        "\n",
        "    return logits, state_h, state_c, weights"
      ],
      "metadata": {
        "id": "-5CYdFnOW9hv"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)"
      ],
      "metadata": {
        "id": "afBd65utWDK8"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_decoder_batch = padded_train_decoder_inputs[:3]\n",
        "print(test_decoder_batch.shape)\n",
        "test_decoder_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jbsavULWFon",
        "outputId": "99c37290-5e8e-420f-d9a2-5eb584d61bd0"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 34)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,   5,  23, 306,  28,   7, 151,   4,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  2,  25,  55, 117, 144,  33,   7,  35, 139, 794,   4,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  2, 105, 306,  17,  24, 225,   4,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_decoder_batch[:, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fck5H0nmWJXr",
        "outputId": "f43b29e5-74ec-4305-8daa-126e72feb9c3"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  5,  25, 105], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_decoder_inputs = tf.expand_dims(test_decoder_batch[:, 1], 1)\n",
        "next_decoder_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq55jm3aWRrJ",
        "outputId": "59861d51-b5cc-4783-e31a-da9b2dc492fb"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
              "array([[  5],\n",
              "       [ 25],\n",
              "       [105]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial values for state_h and state_c are from the encoder.\n",
        "test_decoder_logits, state_h, state_c, test_decoder_weights = test_decoder(\n",
        "    [\n",
        "      next_decoder_inputs,\n",
        "      test_encoder_outputs,\n",
        "      [state_h, state_c]\n",
        "    ])"
      ],
      "metadata": {
        "id": "H8DJtpBeWWbb"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_decoder_logits.shape)\n",
        "print(test_decoder_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8Yq02QeaTKR",
        "outputId": "27fa2b3d-df9d-443b-eb75-972638197078"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 10556)\n",
            "(3, 1, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(targets, logits):\n",
        "  ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  mask = tf.cast(tf.math.not_equal(targets, 0), tf.float32)\n",
        "\n",
        "  return ce_loss(targets, logits, sample_weight=mask)"
      ],
      "metadata": {
        "id": "tCgzOElGb0EY"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((padded_train_encoder_inputs,\n",
        "                                              padded_train_decoder_inputs,\n",
        "                                              padded_train_decoder_targets)).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "5prl2IH-b3Cv"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslatorTrainer(tf.keras.Model):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(TranslatorTrainer, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  # This method will be called by model.fit for each batch.\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      loss = 0.\n",
        "\n",
        "      encoder_input_seq, decoder_input_seq, decoder_target_seq = inputs\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          encoder_output_seq, state_h, state_c = self.encoder(encoder_input_seq)\n",
        "\n",
        "          # We need to create a loop to iterate through the target sequences\n",
        "          for i in range(decoder_target_seq.shape[1]):\n",
        "\n",
        "              # Input to the decoder must have shape of (batch_size, length)\n",
        "              # so we need to expand one dimension (just like in the previous example).\n",
        "              next_decoder_input = tf.expand_dims(decoder_input_seq[:, i], 1)\n",
        "              logits, state_h, state_c, _ = self.decoder(\n",
        "                  [next_decoder_input, encoder_output_seq, (state_h, state_c)])\n",
        "\n",
        "              # The loss is now accumulated through the whole batch\n",
        "              loss += self.loss(decoder_target_seq[:, i], logits)\n",
        "\n",
        "      # Update the parameters and the optimizer\n",
        "      variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "      gradients = tape.gradient(loss, variables)\n",
        "      self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "      return {'loss': loss / decoder_target_seq.shape[1]}"
      ],
      "metadata": {
        "id": "0Af4vblDb-6R"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(source_vocab_size, embedding_dim, hidden_dim)\n",
        "decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "translator_trainer = TranslatorTrainer(encoder, decoder)\n",
        "translator_trainer.compile(optimizer=optimizer, loss=loss_func)"
      ],
      "metadata": {
        "id": "sjZp76oXdnKh"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20"
      ],
      "metadata": {
        "id": "98UJcfUecGmn"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/futuremojo/nlp-demystified/raw/main/models/nmt_with_attention/attention_weights.zip\n",
        "!unzip -o attention_weights.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGea7QeJd3kM",
        "outputId": "b33d919f-6a15-4ffd-e7a0-0309c8b097d1"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 18:40:09--  https://github.com/futuremojo/nlp-demystified/raw/main/models/nmt_with_attention/attention_weights.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/models/nmt_with_attention/attention_weights.zip [following]\n",
            "--2023-11-23 18:40:09--  https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/models/nmt_with_attention/attention_weights.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36984175 (35M) [application/zip]\n",
            "Saving to: ‘attention_weights.zip.1’\n",
            "\n",
            "attention_weights.z 100%[===================>]  35.27M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-11-23 18:40:09 (252 MB/s) - ‘attention_weights.zip.1’ saved [36984175/36984175]\n",
            "\n",
            "Archive:  attention_weights.zip\n",
            "  inflating: attention_weights/attention_decoder_weights_ckpt.data-00000-of-00001  \n",
            "  inflating: attention_weights/attention_encoder_weights_ckpt.data-00000-of-00001  \n",
            "  inflating: attention_weights/attention_decoder_weights_ckpt.index  \n",
            "  inflating: attention_weights/attention_encoder_weights_ckpt.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #saving the weights for the use in drive\n",
        "# encoder.save_weights('/content/drive/MyDrive/NLP/attention_encoder_weights_with_dropout_ckpt')\n",
        "# decoder.save_weights('/content/drive/MyDrive/NLP/attention_decoder_weights_with_dropout_ckpt')\n",
        "# !zip -r ./content/drive/MyDrive/NLP/attention_weights.zip ./content/drive/MyDrive/NLP/attention_weights\n",
        "# files.download('/content/drive/MyDrive/NLP/attention_weights.zip')"
      ],
      "metadata": {
        "id": "Drqk-KpNcKao"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading at the same instance for the use rightnow\n",
        "encoder.save_weights('attention_encoder_weights_with_dropout_ckpt')\n",
        "decoder.save_weights('attention_decoder_weights_with_dropout_ckpt')"
      ],
      "metadata": {
        "id": "30rbFv_6cuOC"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.load_weights('attention_weights/attention_encoder_weights_ckpt')\n",
        "decoder.load_weights('attention_weights/attention_decoder_weights_ckpt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOfVF3fYe8nD",
        "outputId": "728d3db6-65d2-4c50-e176-51c03e534490"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7914080d2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_with_attention(sentence: str,\n",
        "                             source_tokenizer, encoder,\n",
        "                             target_tokenizer, decoder,\n",
        "                             max_translated_len = 30):\n",
        "    input_seq = source_tokenizer.texts_to_sequences([sentence])\n",
        "    tokenized = source_tokenizer.sequences_to_texts(input_seq)\n",
        "\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_encoding_len, padding='post')\n",
        "    encoder_output, state_h, state_c  = encoder.predict(input_seq)\n",
        "\n",
        "    current_word = '<sos>'\n",
        "    decoded_sentence = []\n",
        "\n",
        "    while len(decoded_sentence) < max_translated_len:\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = target_tokenizer.word_index[current_word]\n",
        "\n",
        "        logits, state_h, state_c, _ = decoder.predict([target_seq, encoder_output, (state_h, state_c)])\n",
        "        current_token_index = np.argmax(logits[0])\n",
        "\n",
        "        current_word = target_tokenizer.index_word[current_token_index]\n",
        "\n",
        "        if (current_word == '<eos>'):\n",
        "          break\n",
        "\n",
        "        decoded_sentence.append(current_word)\n",
        "\n",
        "    return tokenized[0], ' '.join(decoded_sentence)"
      ],
      "metadata": {
        "id": "Ld1c3kwzdQDK"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentences(sentences, translation_func, source_tokenizer, encoder,\n",
        "                        target_tokenizer, decoder):\n",
        "  translations = {'Tokenized Original': [], 'Reference': [], 'Translation': []}\n",
        "\n",
        "  for s in sentences:\n",
        "    source, target = s.split(separator)\n",
        "    source = preprocess_sentence(source)\n",
        "    tokenized_sentence, translated = translation_func(source, source_tokenizer, encoder,\n",
        "                                                      target_tokenizer, decoder)\n",
        "\n",
        "    translations['Tokenized Original'].append(tokenized_sentence)\n",
        "    translations['Reference'].append(target)\n",
        "    translations['Translation'].append(translated)\n",
        "\n",
        "  return translations"
      ],
      "metadata": {
        "id": "Oy6wA14cfOqM"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the modal"
      ],
      "metadata": {
        "id": "I4ZFleSofy-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('hun_eng_pairs_test.txt') as file:\n",
        "  test = [line.rstrip() for line in file]"
      ],
      "metadata": {
        "id": "ImpxOwzLf21s"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess test dataset\n",
        "padded_test_encoder_inputs, padded_test_decoder_inputs, padded_test_decoder_targets = process_dataset(test)"
      ],
      "metadata": {
        "id": "ekThFDkUf5JV"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random.seed is just here to re-create results.\n",
        "random.seed(1)\n",
        "sentences = random.sample(test, 25)\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FDSCDRfjK7",
        "outputId": "ee5d9468-a2ac-4993-8195-531b4874c3c4"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Csinálom.<sep>I got it.',\n",
              " 'Mondd el nekem.<sep>Let me know.',\n",
              " 'Ritkán járok oda.<sep>I rarely go there.',\n",
              " \"Mi a döntésed?<sep>What's your decision?\",\n",
              " \"Hol van a legközelebbi étterem?<sep>Where's the closest restaurant?\",\n",
              " 'Mégis csak van egy megoldás.<sep>There is a solution though.',\n",
              " 'Csak pár diák maradt az osztályteremben.<sep>There were few students left in the classroom.',\n",
              " 'Nagyra értékelem a segítségedet ebben.<sep>I appreciate your help on this.',\n",
              " 'Ez az utolsó vonat.<sep>This is the last train.',\n",
              " 'Milyen gyakran jönnek a buszok?<sep>How often do buses come?',\n",
              " \"A boldogság nem tart örökké.<sep>Happiness doesn't last forever.\",\n",
              " \"Azért vagyok itt, hogy bocsánatot kérjek.<sep>I'm here to apologize.\",\n",
              " \"Tom szörnyű szakács, ugye?<sep>Tom is a terrible cook, isn't he?\",\n",
              " \"Gondolod, hogy ma esni fog?<sep>Do you think it'll rain today?\",\n",
              " 'Tom ismeri a járást.<sep>Tom knows the way.',\n",
              " 'Egy régi barátom jött el hozzám vendégségbe.<sep>An old friend came to my house for a visit.',\n",
              " 'Sajnos, tegnap esett az eső.<sep>Unfortunately, it rained yesterday.',\n",
              " 'Legyél szíves várakozni.<sep>Please wait.',\n",
              " 'Bárcsak fele olyan jól tudnék franciául, mint te.<sep>I wish I could speak French half as well as you.',\n",
              " \"Menjünk vissza dolgozni.<sep>Let's all get back to work.\",\n",
              " \"Ennyire hülyék azért nem vagyunk.<sep>We're not that stupid.\",\n",
              " 'Menj átöltözni!<sep>Go get changed.',\n",
              " \"Ne szólj közbe, ha én beszélek.<sep>Don't interrupt me while I'm speaking.\",\n",
              " \"Csak tévét nézek.<sep>I'm just watching TV.\",\n",
              " 'Tom gyorsabban tud úszni mint bárki más, akit ismerek.<sep>Tom can swim faster than anyone else I know.']"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shorter_translations_w_attention = pd.DataFrame(translate_sentences(sentences, translate_with_attention,\n",
        "                                                                    source_tokenizer, encoder,                                                                  target_tokenizer, decoder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE_4-4cpdQ_A",
        "outputId": "955f7445-e1aa-4ca2-a432-c3f37304804c"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shorter_translations_w_attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "ZQHejrElgXj7",
        "outputId": "9fa38e91-eb06-4771-f691-da2d38485819"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Tokenized Original  \\\n",
              "0                                    csinalom .   \n",
              "1                              mondd el nekem .   \n",
              "2                            ritkan jarok oda .   \n",
              "3                               mi a dontesed ?   \n",
              "4              hol van a legkozelebbi etterem ?   \n",
              "5                 megis csak van egy megoldas .   \n",
              "6     csak par diak maradt az osztalyteremben .   \n",
              "7       nagyra ertekelem a segitsegedet ebben .   \n",
              "8                          ez az utolso vonat .   \n",
              "9              milyen gyakran jonnek a buszok ?   \n",
              "10                a boldogsag nem tart orokke .   \n",
              "11  azert vagyok itt , hogy bocsanatot kerjek .   \n",
              "12                 tom szornyu szakacs , ugye ?   \n",
              "13                gondolod , hogy ma esni fog ?   \n",
              "14                         tom ismeri a <unk> .   \n",
              "\n",
              "                                         Reference  \\\n",
              "0                                        I got it.   \n",
              "1                                     Let me know.   \n",
              "2                               I rarely go there.   \n",
              "3                            What's your decision?   \n",
              "4                  Where's the closest restaurant?   \n",
              "5                      There is a solution though.   \n",
              "6   There were few students left in the classroom.   \n",
              "7                  I appreciate your help on this.   \n",
              "8                          This is the last train.   \n",
              "9                         How often do buses come?   \n",
              "10                 Happiness doesn't last forever.   \n",
              "11                          I'm here to apologize.   \n",
              "12               Tom is a terrible cook, isn't he?   \n",
              "13                  Do you think it'll rain today?   \n",
              "14                              Tom knows the way.   \n",
              "\n",
              "                                          Translation  \n",
              "0                                      i'm doing it .  \n",
              "1                                           tell me .  \n",
              "2                                 i rarely go there .  \n",
              "3                             what is your decision ?  \n",
              "4                       where's the nearest package ?  \n",
              "5                          there is no one solution .  \n",
              "6   there were only a few students left in the cla...  \n",
              "7                            i appreciate your help .  \n",
              "8                            this is the last train .  \n",
              "9                       how often do the buses come ?  \n",
              "10                 happiness is not forever forever .  \n",
              "11                            i'm here to apologize .  \n",
              "12                tom is a terrible cook , isn't he ?  \n",
              "13            do you think it's going to rain today ?  \n",
              "14                               tom knows his mind .  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e4c0792-da91-4140-b48d-151387344b27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokenized Original</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>csinalom .</td>\n",
              "      <td>I got it.</td>\n",
              "      <td>i'm doing it .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mondd el nekem .</td>\n",
              "      <td>Let me know.</td>\n",
              "      <td>tell me .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ritkan jarok oda .</td>\n",
              "      <td>I rarely go there.</td>\n",
              "      <td>i rarely go there .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mi a dontesed ?</td>\n",
              "      <td>What's your decision?</td>\n",
              "      <td>what is your decision ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hol van a legkozelebbi etterem ?</td>\n",
              "      <td>Where's the closest restaurant?</td>\n",
              "      <td>where's the nearest package ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>megis csak van egy megoldas .</td>\n",
              "      <td>There is a solution though.</td>\n",
              "      <td>there is no one solution .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>csak par diak maradt az osztalyteremben .</td>\n",
              "      <td>There were few students left in the classroom.</td>\n",
              "      <td>there were only a few students left in the cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>nagyra ertekelem a segitsegedet ebben .</td>\n",
              "      <td>I appreciate your help on this.</td>\n",
              "      <td>i appreciate your help .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ez az utolso vonat .</td>\n",
              "      <td>This is the last train.</td>\n",
              "      <td>this is the last train .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>milyen gyakran jonnek a buszok ?</td>\n",
              "      <td>How often do buses come?</td>\n",
              "      <td>how often do the buses come ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>a boldogsag nem tart orokke .</td>\n",
              "      <td>Happiness doesn't last forever.</td>\n",
              "      <td>happiness is not forever forever .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>azert vagyok itt , hogy bocsanatot kerjek .</td>\n",
              "      <td>I'm here to apologize.</td>\n",
              "      <td>i'm here to apologize .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tom szornyu szakacs , ugye ?</td>\n",
              "      <td>Tom is a terrible cook, isn't he?</td>\n",
              "      <td>tom is a terrible cook , isn't he ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>gondolod , hogy ma esni fog ?</td>\n",
              "      <td>Do you think it'll rain today?</td>\n",
              "      <td>do you think it's going to rain today ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>tom ismeri a &lt;unk&gt; .</td>\n",
              "      <td>Tom knows the way.</td>\n",
              "      <td>tom knows his mind .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e4c0792-da91-4140-b48d-151387344b27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e4c0792-da91-4140-b48d-151387344b27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e4c0792-da91-4140-b48d-151387344b27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b9465e9-ff34-4ab0-a915-e2d4969d3330\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b9465e9-ff34-4ab0-a915-e2d4969d3330')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b9465e9-ff34-4ab0-a915-e2d4969d3330 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = train.copy()\n",
        "pairs.sort(key=lambda s: len(s))\n",
        "longer_sentences = pairs[-10:]\n",
        "longer_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G2lznsdimxK",
        "outputId": "e2e2ea67-c940-4cc9-d839-ae8bf7943133"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['- Tegnap este mikor mentél aludni? - 4 órakor. - Micsoda? Mit csináltál olyan sokáig? - Telefonon beszélgettem a volt barátommal.<sep>\"When\\'d you go to sleep last night?\" \"4 o\\'clock.\" \"What? What were you doing up so late?\" \"Talking on the phone with my ex-boyfriend.\"',\n",
              " 'Mi az öregség? Először a neveket felejted el, majd az arcokat, utána elfelejted felhúzni a cipzáradat, aztán elfelejted lehúzni.<sep>What is old age? First you forget names, then you forget faces, then you forget to pull your zipper up, then you forget to pull it down.',\n",
              " \"Bár a Föld felületének csupán két százalékát borítják őserdők, ott él a világon fellelhető állat-, növény- és rovarfaj fele.<sep>Although rainforests make up only two percent of the earth's surface, over half the world's wild plant, animal and insect species live there.\",\n",
              " \"Amikor gyerek volt Tom, összegyűjtötte az apja cigarettacsikkjeit, míg elég nem lett a dohány, hogy sodorjon egy szál cigarettát magának.<sep>When Tom was a kid, he used to collect his father's cigarette butts until he had enough tobacco to roll a cigarette for himself.\",\n",
              " 'Nemrég, ahogy sétáltam a járdán, egy autó száguldott el mellettem és vizet fröcskölt rám. Ezt nézd meg! A szoknyám és a cipőm csupa sár.<sep>Earlier, as I was walking down the sidewalk, a car drove by and splashed water on me. Look at this! My skirt and shoes are all muddy.',\n",
              " \"Sok fiatal, akinek piercingje van, egész életében kitart a párja mellett, különösen ha az egyik orrkarikája beakad a másik fogszabályozójába.<sep>Many young people with piercings stay together their whole lives, especially if one gets their nose ring stuck in the other's braces.\",\n",
              " \"Ne adj kölcsön könyveket; senki nem adja őket vissza. Csupán olyan könyvek maradtak a könyvtáramban, amiket én kaptam kölcsön más emberektől.<sep>Don't lend books; no one gives them back. The only books that are still left in my library are ones that I have borrowed from other people.\",\n",
              " 'A Tatoeba Korpusban a hibák számának csökkentésének egyik módja az lenne, hogy arra biztassuk az embereket, hogy csak a saját anyanyelvükre fordítsanak.<sep>One way to lower the number of errors in the Tatoeba Corpus would be to encourage people to only translate into their native languages.',\n",
              " 'A Tatoeba projekt, amely megtalálható az interneten a tatoeba.org oldalon, azon dolgozik, hogy létrejöjjön egy nagy adatbázis mondatokból és azok sok-sok nyelvű fordításából.<sep>The Tatoeba Project, which can be found online at tatoeba.org, is working on creating a large database of example sentences translated into many languages.',\n",
              " 'A busz, amelyik most érkezik, az egyes terminálra megy, a belföldi járatokhoz. Kérem, hogy a nemzetközi járatokkal utazók várakozni szíveskedjenek. A nemzetközi terminálhoz induló busz szintén ebből a megállóból indul.<sep>The bus now arriving is going to Domestic Terminal 1. Passengers for the International Terminal, please wait. The shuttle bus to the International Terminal also leaves from this stop.']"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "longer_translations_with_attention = pd.DataFrame(translate_sentences(longer_sentences, translate_with_attention,\n",
        "                                                                      source_tokenizer, encoder,\n",
        "                                                                      target_tokenizer, decoder))\n",
        "longer_translations_with_attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5981
        },
        "id": "N8rE5jxyjuhR",
        "outputId": "790d44cf-b13a-4dd3-d960-ec69f0b4ded2"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  Tokenized Original  \\\n",
              "0  tegnap este mikor mentel aludni ? 4 orakor . m...   \n",
              "1  mi az oregseg ? eloszor a neveket felejted el ...   \n",
              "2  bar a fold feluletenek csupan ket szazalekat b...   \n",
              "3  amikor gyerek volt tom , osszegyujtotte az apj...   \n",
              "4  nemreg , ahogy setaltam a jardan , egy auto sz...   \n",
              "5  sok fiatal , akinek piercingje van , egesz ele...   \n",
              "6  ne adj kolcson konyveket senki nem adja oket v...   \n",
              "7  a tatoeba korpusban a hibak szamanak csokkente...   \n",
              "8  a tatoeba projekt , amely megtalalhato az inte...   \n",
              "9  a busz , amelyik most erkezik , az egyes termi...   \n",
              "\n",
              "                                           Reference  \\\n",
              "0  \"When'd you go to sleep last night?\" \"4 o'cloc...   \n",
              "1  What is old age? First you forget names, then ...   \n",
              "2  Although rainforests make up only two percent ...   \n",
              "3  When Tom was a kid, he used to collect his fat...   \n",
              "4  Earlier, as I was walking down the sidewalk, a...   \n",
              "5  Many young people with piercings stay together...   \n",
              "6  Don't lend books; no one gives them back. The ...   \n",
              "7  One way to lower the number of errors in the T...   \n",
              "8  The Tatoeba Project, which can be found online...   \n",
              "9  The bus now arriving is going to Domestic Term...   \n",
              "\n",
              "                                         Translation  \n",
              "0  when'd were you out of last night ? 4 o'clock ...  \n",
              "1  what is old age ? first , then you forget to f...  \n",
              "2  though looking only million detectives and 100...  \n",
              "3  when tom was a child , he burned his father's ...  \n",
              "4  earlier , as i was walking down the sidewalk ,...  \n",
              "5  many young people we ate the whole memories we...  \n",
              "6  don't lend books not to return here . the only...  \n",
              "7  one way in the tatoeba number should be able t...  \n",
              "8  the tatoeba project , which can i recommend no...  \n",
              "9  the bus now arriving on domestic terminal , pl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55b05ccf-bc81-4ea0-8d34-87b861df642c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokenized Original</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tegnap este mikor mentel aludni ? 4 orakor . m...</td>\n",
              "      <td>\"When'd you go to sleep last night?\" \"4 o'cloc...</td>\n",
              "      <td>when'd were you out of last night ? 4 o'clock ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mi az oregseg ? eloszor a neveket felejted el ...</td>\n",
              "      <td>What is old age? First you forget names, then ...</td>\n",
              "      <td>what is old age ? first , then you forget to f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bar a fold feluletenek csupan ket szazalekat b...</td>\n",
              "      <td>Although rainforests make up only two percent ...</td>\n",
              "      <td>though looking only million detectives and 100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amikor gyerek volt tom , osszegyujtotte az apj...</td>\n",
              "      <td>When Tom was a kid, he used to collect his fat...</td>\n",
              "      <td>when tom was a child , he burned his father's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nemreg , ahogy setaltam a jardan , egy auto sz...</td>\n",
              "      <td>Earlier, as I was walking down the sidewalk, a...</td>\n",
              "      <td>earlier , as i was walking down the sidewalk ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sok fiatal , akinek piercingje van , egesz ele...</td>\n",
              "      <td>Many young people with piercings stay together...</td>\n",
              "      <td>many young people we ate the whole memories we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ne adj kolcson konyveket senki nem adja oket v...</td>\n",
              "      <td>Don't lend books; no one gives them back. The ...</td>\n",
              "      <td>don't lend books not to return here . the only...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a tatoeba korpusban a hibak szamanak csokkente...</td>\n",
              "      <td>One way to lower the number of errors in the T...</td>\n",
              "      <td>one way in the tatoeba number should be able t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a tatoeba projekt , amely megtalalhato az inte...</td>\n",
              "      <td>The Tatoeba Project, which can be found online...</td>\n",
              "      <td>the tatoeba project , which can i recommend no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a busz , amelyik most erkezik , az egyes termi...</td>\n",
              "      <td>The bus now arriving is going to Domestic Term...</td>\n",
              "      <td>the bus now arriving on domestic terminal , pl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55b05ccf-bc81-4ea0-8d34-87b861df642c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55b05ccf-bc81-4ea0-8d34-87b861df642c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55b05ccf-bc81-4ea0-8d34-87b861df642c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ea7158c-a563-4b58-a0b2-606aa4af8e41\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ea7158c-a563-4b58-a0b2-606aa4af8e41')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ea7158c-a563-4b58-a0b2-606aa4af8e41 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    }
  ]
}